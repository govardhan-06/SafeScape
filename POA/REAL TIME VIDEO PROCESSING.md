To use WebSockets for real-time feedback between your React frontend and a PyTorch backend, you can follow these steps:

### 1. **Set Up WebSocket Server with FastAPI**

1. **Install Dependencies**:
   - Install FastAPI and WebSocket libraries:
     ```bash
     pip install fastapi[all] websockets torch
     ```

2. **Create a WebSocket Server**:
   - Set up a FastAPI server with WebSocket support. Hereâ€™s an example of a FastAPI server handling video frames:
     ```python
     from fastapi import FastAPI, WebSocket
     import torch
     from io import BytesIO
     from PIL import Image

     app = FastAPI()

     # Load your trained PyTorch model
     model = torch.load('model.pth')
     model.eval()

     @app.websocket("/ws/video")
     async def websocket_endpoint(websocket: WebSocket):
         await websocket.accept()
         while True:
             # Receive frame from client
             data = await websocket.receive_bytes()
             
             # Process frame
             image = Image.open(BytesIO(data))
             tensor = transform(image).unsqueeze(0)  # Apply transformations and add batch dimension
             with torch.no_grad():
                 predictions = model(tensor)
             
             # Send results back to client
             await websocket.send_json({"predictions": predictions.tolist()})
     ```

   - Replace `transform(image)` with the actual preprocessing required for your model.

### 2. **Integrate WebSocket Client in React**

1. **Install WebSocket Library**:
   - You can use the native WebSocket API or a library like `socket.io-client`:
     ```bash
     npm install socket.io-client
     ```

2. **Create WebSocket Client Component**:
   - Implement a React component to handle video frames and WebSocket communication:
     ```javascript
     import React, { useRef, useEffect } from 'react';
     import io from 'socket.io-client';

     const socket = io('ws://localhost:8000/ws/video');

     function VideoProcessing() {
       const videoRef = useRef(null);
       const canvasRef = useRef(null);

       useEffect(() => {
         const video = videoRef.current;
         const canvas = canvasRef.current;
         const ctx = canvas.getContext('2d');

         const handleFrame = async () => {
           if (video && video.readyState === video.HAVE_ENOUGH_DATA) {
             // Draw video frame to canvas
             canvas.width = video.videoWidth;
             canvas.height = video.videoHeight;
             ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

             // Get image data
             const frameData = canvas.toDataURL('image/jpeg');

             // Send image data to WebSocket server
             socket.send(frameData);
           }
         };

         // Handle incoming predictions
         socket.on('message', (data) => {
           const predictions = JSON.parse(data);
           // Process predictions and update UI (draw bounding boxes, labels, etc.)
         });

         // Send video frames periodically
         const interval = setInterval(handleFrame, 1000 / 30); // 30 FPS

         return () => clearInterval(interval);
       }, []);

       return (
         <div>
           <video ref={videoRef} controls autoPlay />
           <canvas ref={canvasRef} />
         </div>
       );
     }

     export default VideoProcessing;
     ```

### 3. **Run and Test**

1. **Start FastAPI Server**:
   - Run your FastAPI server:
     ```bash
     uvicorn main:app --reload
     ```

2. **Run React App**:
   - Start your React app:
     ```bash
     npm start
     ```

3. **Test the Setup**:
   - Upload a video in your React app.
   - Ensure video frames are sent to the FastAPI server via WebSocket and results are displayed in real-time on the frontend.

### Summary

This setup ensures that video processing and inference are handled on the server side, while the React frontend handles real-time communication and visualization. Using WebSockets provides low latency and efficient data exchange, which is crucial for real-time applications.